{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of get_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krisivarga/deep_learning_HW_big/blob/Kristof_solve/Copy_of_get_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoHgWQEW4Z1X"
      },
      "source": [
        "As the first task, we download the given dataset from   http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html . We chose the xml format, as it seems to be better structured and has fewer invalid rows."
      ],
      "id": "IoHgWQEW4Z1X"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d17b8c13"
      },
      "source": [
        "#download file from web\n",
        "\n",
        "import requests, zipfile, io, os\n",
        "\n",
        "zip_file_url = \"http://groups.di.unipi.it/~gulli/newsspace200.xml.bz\"\n",
        "\n",
        "filename = zip_file_url.split(\"/\")[-1]\n",
        "with open(filename, \"wb\") as f:\n",
        "    r = requests.get(zip_file_url)\n",
        "    f.write(r.content)"
      ],
      "id": "d17b8c13",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b2c4cfa",
        "outputId": "5333e2a5-44cb-4f27-bda6-8b0b0cca0fb6"
      },
      "source": [
        "#create data folder, decompress data\n",
        "\n",
        "import bz2,shutil\n",
        "\n",
        "dirName = 'data'\n",
        "try:\n",
        "    # Create target Directory\n",
        "    os.mkdir(dirName)\n",
        "    print(\"Directory \" , dirName ,  \" Created \") \n",
        "except FileExistsError:\n",
        "    print(\"Directory \" , dirName ,  \" already exists\")\n",
        "    \n",
        "    \n",
        "with bz2.BZ2File(\"newsspace200.xml.bz\") as fr, open(\"./data/input.xml\",\"wb\") as fw:\n",
        "    shutil.copyfileobj(fr,fw)"
      ],
      "id": "4b2c4cfa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory  data  already exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "142157c9"
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "tree = ET.parse(\"./data/input.xml\")\n",
        "root = tree.getroot()\n",
        "\n",
        "titles = []\n",
        "categories = []\n",
        "descriptions = []\n",
        "sources = []\n",
        "\n",
        "\n",
        "for title in tree.findall('title'):\n",
        "    titles.append(title.text)\n",
        "    \n",
        "for category in tree.findall('category'):\n",
        "        categories.append(category.text)\n",
        "\n",
        "for description in tree.findall('description'):\n",
        "    descriptions.append(description.text)\n",
        "\n",
        "for source in tree.findall('source'):\n",
        "    sources.append(source.text)\n"
      ],
      "id": "142157c9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c64721c"
      },
      "source": [
        "import numpy as np"
      ],
      "id": "5c64721c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "593363e4"
      },
      "source": [
        "titles = np.array(titles).T\n",
        "categories = np.array(categories).T\n",
        "descriptions = np.array(descriptions).T\n",
        "sources = np.array(sources).T"
      ],
      "id": "593363e4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28313a56"
      },
      "source": [
        "data = np.dstack((sources,titles,descriptions,categories)).reshape(len(titles),4)"
      ],
      "id": "28313a56",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bb2a4a8",
        "outputId": "b18553eb-6c4f-4005-e7b7-ecc861305118"
      },
      "source": [
        "data.shape"
      ],
      "id": "3bb2a4a8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(496835, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21e33b2f"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.columns = ['source','title', 'desc', 'cat']"
      ],
      "id": "21e33b2f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b4d9a31",
        "outputId": "69e02dd0-922d-4b71-ce9b-3fae2c04c7a0"
      },
      "source": [
        "print(f\"Total unique categories are: {len(df['cat'].value_counts())}\")\n",
        "print(f\"Count of occurance of each category:\")\n",
        "df['cat'].value_counts()"
      ],
      "id": "1b4d9a31",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique categories are: 17\n",
            "Count of occurance of each category:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "World                                                                                                                                                                                       81456\n",
              "Entertainment                                                                                                                                                                               70892\n",
              "Sports                                                                                                                                                                                      62163\n",
              "Business                                                                                                                                                                                    56656\n",
              "Top Stories                                                                                                                                                                                 56045\n",
              "Sci/Tech                                                                                                                                                                                    41194\n",
              "Top News                                                                                                                                                                                    31917\n",
              "Europe                                                                                                                                                                                      30905\n",
              "Health                                                                                                                                                                                      19915\n",
              "Italia                                                                                                                                                                                      13814\n",
              "U.S.                                                                                                                                                                                        13770\n",
              "Software and Developement                                                                                                                                                                    2739\n",
              "Toons                                                                                                                                                                                        2150\n",
              "Music Feeds                                                                                                                                                                                  1207\n",
              "5                                                                                                                                                                                             106\n",
              "The recent onslaught of hurricanes has prompted some media outlets to mention  quot;global warming quot; as a possible cause, but a team of climate researchers set the record straight.        1\n",
              "ProEnglish, a national organization that wants to make English the official language of US government operations, is suing the Department of Health and Human Services over a                   1\n",
              "Name: cat, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8779b3dc",
        "outputId": "db99e5da-adf6-42b9-aa64-ed6fb5b591d2"
      },
      "source": [
        "selected_cats = df['cat'].value_counts()[:5].index.tolist()\n",
        "print(selected_cats)\n",
        "\n",
        "df_selected = df.loc[df['cat'].isin(selected_cats)]\n",
        "\n",
        "print(df_selected)"
      ],
      "id": "8779b3dc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['World', 'Entertainment', 'Sports', 'Business', 'Top Stories']\n",
            "                       source  ...       cat\n",
            "0              Yahoo Business  ...  Business\n",
            "1              Yahoo Business  ...  Business\n",
            "2              Yahoo Business  ...  Business\n",
            "3              Yahoo Business  ...  Business\n",
            "4              Yahoo Business  ...  Business\n",
            "...                       ...  ...       ...\n",
            "496829  New York Times sports  ...    Sports\n",
            "496830         BBC News world  ...     World\n",
            "496831  New York Times sports  ...    Sports\n",
            "496832         BBC News world  ...     World\n",
            "496833  New York Times sports  ...    Sports\n",
            "\n",
            "[327212 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca0f1346",
        "outputId": "7faebc5f-6787-4a55-a9e8-7db8c0c4b881"
      },
      "source": [
        "print(f\"Total unique categories are: {len(df_selected['cat'].value_counts())}\")\n",
        "print(f\"Count of occurance of each category:\")\n",
        "df_selected['cat'].value_counts()"
      ],
      "id": "ca0f1346",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique categories are: 5\n",
            "Count of occurance of each category:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "World            81456\n",
              "Entertainment    70892\n",
              "Sports           62163\n",
              "Business         56656\n",
              "Top Stories      56045\n",
              "Name: cat, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6410012a",
        "outputId": "cd71ef2a-e54e-4255-a8ac-990978c23748"
      },
      "source": [
        "df_selected.isnull().sum()"
      ],
      "id": "6410012a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "source       0\n",
              "title        0\n",
              "desc      2415\n",
              "cat          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7896c8a"
      },
      "source": [
        "df_selected = df_selected.dropna()"
      ],
      "id": "e7896c8a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2139c2f4",
        "outputId": "bf28b154-b958-4139-fc87-48d9bdad7fed"
      },
      "source": [
        "df_selected.isnull().sum()"
      ],
      "id": "2139c2f4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "source    0\n",
              "title     0\n",
              "desc      0\n",
              "cat       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef5b41e9",
        "outputId": "4dc76f78-a594-4a95-df50-80a6c293fd77"
      },
      "source": [
        "# Check of spaces in column headline - using enumerate\n",
        "spaces = []\n",
        "for i, x in enumerate(df_selected['title']):\n",
        "    if type(x) == str:\n",
        "        if x.isspace():\n",
        "            spaces.append(i)\n",
        "        \n",
        "print(len(spaces), 'spaces in index: ', spaces)"
      ],
      "id": "ef5b41e9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 spaces in index:  []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19890e6c",
        "outputId": "7e5a4ab7-b5ee-4aff-d48f-13fb1156f329"
      },
      "source": [
        "# Check of spaces in column short desc - using itertuples\n",
        "blanks = []  # start with an empty list\n",
        "\n",
        "for i,sou,tit,desc,cat in df_selected.itertuples():  # iterate over the DataFrame\n",
        "    if type(desc)==str:            # avoid NaN values\n",
        "        if desc.isspace():         # test 'review' for whitespace\n",
        "            blanks.append(i)     # add matching index numbers to the list\n",
        "        \n",
        "print(len(blanks), 'blanks: ', blanks)"
      ],
      "id": "19890e6c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 blanks:  []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3NhBkuRXSMr"
      },
      "source": [
        "Although it is part of the database, we are not going to use the 'source' field. When we print the value_counts for that field joined with the categories, it's obvious that the category can be found in the 'source' most of the time, which defeats the point of this homework."
      ],
      "id": "U3NhBkuRXSMr"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sQTGIElRIPN",
        "outputId": "d8510866-295e-4a32-9943-7426b892b367"
      },
      "source": [
        "print(df_selected['source'].value_counts())\n",
        "print(df_selected.value_counts(subset=['source','cat'])[:30])\n",
        "print(df_selected.value_counts(subset=['source','cat'])[100:130])"
      ],
      "id": "9sQTGIElRIPN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reuters                        15935\n",
            "Yahoo World                    11193\n",
            "RedNova general                 7855\n",
            "Reuters Business                6897\n",
            "Yahoo Sports                    6850\n",
            "                               ...  \n",
            "Mt. Vernon Register News           1\n",
            "SuperMizzou                        1\n",
            "Rome News-Tribune                  1\n",
            "The Hammer                         1\n",
            "Internet Telephony Magazine        1\n",
            "Name: source, Length: 3053, dtype: int64\n",
            "source                      cat          \n",
            "Yahoo World                 World            11193\n",
            "RedNova general             World             7855\n",
            "Reuters Business            Business          6897\n",
            "Yahoo Sports                Sports            6850\n",
            "Yahoo Entertainment         Entertainment     6741\n",
            "Reuters World               World             6106\n",
            "BBC News world              World             6038\n",
            "Yahoo Politics              World             4586\n",
            "New York Times sports       Sports            4361\n",
            "Reuters                     Top Stories       3710\n",
            "                            Business          3659\n",
            "                            Entertainment     3547\n",
            "Forbes                      Business          3346\n",
            "Yahoo Business              Business          3053\n",
            "Reuters Sports              Sports            3007\n",
            "San Francisco Chronicle     Sports            2575\n",
            "The Washington Post sports  Sports            2567\n",
            "Reuters                     World             2548\n",
            "                            Sports            2471\n",
            "New York Times world        World             2469\n",
            "The Motley Fool             Business          2196\n",
            "The Washington Post world   World             2091\n",
            "Reuters Entertainment       Entertainment     1984\n",
            "New York Times Business     Business          1760\n",
            "Boston Globe world          World             1735\n",
            "Boston Globe business       Business          1735\n",
            "Bloomberg                   Business          1718\n",
            "Xinhua                      World             1655\n",
            "ABC News                    Top Stories       1617\n",
            "                            Entertainment     1562\n",
            "dtype: int64\n",
            "source                      cat          \n",
            "CNN International           Entertainment    533\n",
            "ABC News                    Sports           532\n",
            "Turkish Press               World            531\n",
            "Canada.com                  Sports           529\n",
            "Seattle Post Intelligencer  Top Stories      527\n",
            "Washington Post             World            526\n",
            "Seattle Post Intelligencer  Entertainment    525\n",
            "Guardian                    Sports           522\n",
            "Telegraph.co.uk             Sports           519\n",
            "Independent                 Top Stories      518\n",
            "                            World            518\n",
            "Rediff Movies               Entertainment    503\n",
            "Independent                 Entertainment    502\n",
            "Houston Chronicle           Sports           486\n",
            "Xinhua                      Sports           483\n",
            "Reuters Life and Leisure    Entertainment    476\n",
            "Houston Chronicle           Top Stories      475\n",
            "CBC News                    Top Stories      468\n",
            "Telegraph.co.uk             Top Stories      467\n",
            "Houston Chronicle           Entertainment    466\n",
            "Xinhua                      Business         466\n",
            "Telegraph.co.uk             Entertainment    464\n",
            "CBC News                    Entertainment    460\n",
            "TSN.ca                      Sports           459\n",
            "Boston Globe                World            458\n",
            "USA Today                   Business         453\n",
            "The Australian              World            446\n",
            "Seattle Post Intelligencer  Sports           439\n",
            "MLB.com                     Sports           431\n",
            "Al-Jazeera                  World            428\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwdmfcVAWAyT"
      },
      "source": [
        "Next, we define tokenization and vocabulary building. We're using the WordPiece based BERT tokenizer from huggingface.co. We also tried the SentencePie based XLNetTokenizer, but the results weren't as good as with the BERT tokenizer. The methods that are defined here will be applied to every line of the dataframe.  \n",
        "We decided on one method, which tokenizes the title and the description and after that, it removes the tokens that contain non-aplhanumeric characters (except padding (# in BERT) or a few other characters). We do this, because some descriptions contain obviously unwanted characters, like '\\\\'. We build the vocabualry from these tokens.  \n",
        "The other method uses the encode_plus function which automatically \n"
      ],
      "id": "DwdmfcVAWAyT"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seMABop5RPtq",
        "outputId": "6a576991-7c64-4138-830f-8638ba220277"
      },
      "source": [
        "!pip install sentencepiece\n",
        "!pip install transformers\n",
        "from transformers import XLNetTokenizer\n",
        "from transformers import BertTokenizer\n",
        "import re\n",
        "\n",
        "bertregex = re.compile('^[a-zA-Z\"]+$')\n",
        "xlregex = re.compile('^[a-zA-Z0-9\\_\\-\\'\"]+$')\n",
        "\n",
        "xltokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
        "\n",
        "btokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n"
      ],
      "id": "seMABop5RPtq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.19)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nktcet9mRYBu",
        "outputId": "66ed43f0-4af6-4e97-e396-d185c100431f"
      },
      "source": [
        "bertvoc = []\n",
        "bertidvoc= []\n",
        "\n",
        "def tr(bt,reg,voc,idvoc,title,sz):\n",
        "  a = bt.tokenize(title + \" \" + sz)\n",
        "  r = []\n",
        "  for s in a:\n",
        "    if reg.match(s) is not None:     \n",
        "      r.append(s)\n",
        "  voc.extend(r)\n",
        "  return r\n",
        "\n",
        "df_selected['bertencode'] = df_selected.apply(lambda row: tr(btokenizer, bertregex,bertvoc,bertidvoc, str(row['title']), str(row['desc'])), axis=1)\n",
        "print(df_selected)"
      ],
      "id": "nktcet9mRYBu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       source  ...                                         bertencode\n",
            "0              Yahoo Business  ...  [wall, st, pull, reflects, tech, blow, reuters...\n",
            "1              Yahoo Business  ...  [wall, st, bears, claw, back, into, the, black...\n",
            "2              Yahoo Business  ...  [carly, looks, toward, commercial, aerospace, ...\n",
            "3              Yahoo Business  ...  [oil, and, economy, cloud, stocks, outlook, re...\n",
            "4              Yahoo Business  ...  [iraq, halt, oil, exports, from, main, souther...\n",
            "...                       ...  ...                                                ...\n",
            "496829  New York Times sports  ...  [high, on, priority, list, home, improvement, ...\n",
            "496830         BBC News world  ...  [compromise, seals, climate, meeting, a, clima...\n",
            "496831  New York Times sports  ...  [e, enjoying, his, point, of, view, howard, e,...\n",
            "496832         BBC News world  ...  [iraqi, judges, quiz, chemical, ali, ali, hass...\n",
            "496833  New York Times sports  ...  [nets, get, carter, from, rap, indianapolis, a...\n",
            "\n",
            "[324797 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "cvY4_vHQa17S",
        "outputId": "ca3e0980-63f8-4bef-b3cd-57e700107be3"
      },
      "source": [
        "bertencidvoc = []\n",
        "def bertenc(bt,voc,title,sz):\n",
        "  text_to_encode = title + \" \" + sz\n",
        "  a = bt.encode_plus(\n",
        "            text_to_encode, \n",
        "            max_length= 512, \n",
        "            add_special_tokens=True,\n",
        "            return_token_type_ids=False, \n",
        "            padding=\"max_length\",\n",
        "            truncation = True,\n",
        "            return_attention_mask=False\n",
        "        )\n",
        "  ids = a['input_ids']\n",
        "  voc.extend(ids)\n",
        "  return ids\n",
        "\n",
        "df_selected['bertencodeplus'] = df_selected.apply(lambda row: bertenc(btokenizer, bertencidvoc, str(row['title']), str(row['desc'])), axis=1)\n",
        "\n",
        "#df_selected['xl'] = df_selected.apply(lambda row: tr(xltokenizer, xlregex,xlvoc, str(row['title']), str(row['desc'])), axis=1)\n",
        "df_selected"
      ],
      "id": "cvY4_vHQa17S",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>title</th>\n",
              "      <th>desc</th>\n",
              "      <th>cat</th>\n",
              "      <th>bertencode</th>\n",
              "      <th>bertencodeplus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Yahoo Business</td>\n",
              "      <td>Wall St. Pullback Reflects Tech Blowout (Reuters)</td>\n",
              "      <td>Reuters - Wall Street's long-playing drama,\\\"W...</td>\n",
              "      <td>Business</td>\n",
              "      <td>[wall, st, pull, reflects, tech, blow, reuters...</td>\n",
              "      <td>[101, 2813, 2358, 1012, 4139, 5963, 11138, 662...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Yahoo Business</td>\n",
              "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
              "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
              "      <td>Business</td>\n",
              "      <td>[wall, st, bears, claw, back, into, the, black...</td>\n",
              "      <td>[101, 2813, 2358, 1012, 6468, 15020, 2067, 204...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Yahoo Business</td>\n",
              "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
              "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
              "      <td>Business</td>\n",
              "      <td>[carly, looks, toward, commercial, aerospace, ...</td>\n",
              "      <td>[101, 18431, 2571, 3504, 2646, 3293, 13395, 10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Yahoo Business</td>\n",
              "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
              "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
              "      <td>Business</td>\n",
              "      <td>[oil, and, economy, cloud, stocks, outlook, re...</td>\n",
              "      <td>[101, 3514, 1998, 4610, 6112, 15768, 1005, 176...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Yahoo Business</td>\n",
              "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
              "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
              "      <td>Business</td>\n",
              "      <td>[iraq, halt, oil, exports, from, main, souther...</td>\n",
              "      <td>[101, 5712, 9190, 2015, 3514, 14338, 2013, 236...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496829</th>\n",
              "      <td>New York Times sports</td>\n",
              "      <td>High on priority list: Home improvement</td>\n",
              "      <td>Doc Rivers knows any postseason plans hinge on...</td>\n",
              "      <td>Sports</td>\n",
              "      <td>[high, on, priority, list, home, improvement, ...</td>\n",
              "      <td>[101, 2152, 2006, 9470, 2862, 1024, 2188, 7620...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496830</th>\n",
              "      <td>BBC News world</td>\n",
              "      <td>Compromise seals climate meeting</td>\n",
              "      <td>A climate conference overcomes last-minute obj...</td>\n",
              "      <td>World</td>\n",
              "      <td>[compromise, seals, climate, meeting, a, clima...</td>\n",
              "      <td>[101, 12014, 13945, 4785, 3116, 1037, 4785, 30...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496831</th>\n",
              "      <td>New York Times sports</td>\n",
              "      <td>Eisley enjoying his point of view</td>\n",
              "      <td>Howard Eisley has fond memories of Boston. He ...</td>\n",
              "      <td>Sports</td>\n",
              "      <td>[e, enjoying, his, point, of, view, howard, e,...</td>\n",
              "      <td>[101, 1041, 2483, 3051, 9107, 2010, 2391, 1997...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496832</th>\n",
              "      <td>BBC News world</td>\n",
              "      <td>Iraqi judges quiz 'Chemical Ali'</td>\n",
              "      <td>Ali Hassan al-Majid - widely known as Chemical...</td>\n",
              "      <td>World</td>\n",
              "      <td>[iraqi, judges, quiz, chemical, ali, ali, hass...</td>\n",
              "      <td>[101, 8956, 6794, 19461, 1005, 5072, 4862, 100...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496833</th>\n",
              "      <td>New York Times sports</td>\n",
              "      <td>Nets get Carter from Raptors</td>\n",
              "      <td>INDIANAPOLIS -- All-Star Vince Carter was trad...</td>\n",
              "      <td>Sports</td>\n",
              "      <td>[nets, get, carter, from, rap, indianapolis, a...</td>\n",
              "      <td>[101, 16996, 2131, 5708, 2013, 9680, 6591, 950...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>324797 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       source  ...                                     bertencodeplus\n",
              "0              Yahoo Business  ...  [101, 2813, 2358, 1012, 4139, 5963, 11138, 662...\n",
              "1              Yahoo Business  ...  [101, 2813, 2358, 1012, 6468, 15020, 2067, 204...\n",
              "2              Yahoo Business  ...  [101, 18431, 2571, 3504, 2646, 3293, 13395, 10...\n",
              "3              Yahoo Business  ...  [101, 3514, 1998, 4610, 6112, 15768, 1005, 176...\n",
              "4              Yahoo Business  ...  [101, 5712, 9190, 2015, 3514, 14338, 2013, 236...\n",
              "...                       ...  ...                                                ...\n",
              "496829  New York Times sports  ...  [101, 2152, 2006, 9470, 2862, 1024, 2188, 7620...\n",
              "496830         BBC News world  ...  [101, 12014, 13945, 4785, 3116, 1037, 4785, 30...\n",
              "496831  New York Times sports  ...  [101, 1041, 2483, 3051, 9107, 2010, 2391, 1997...\n",
              "496832         BBC News world  ...  [101, 8956, 6794, 19461, 1005, 5072, 4862, 100...\n",
              "496833  New York Times sports  ...  [101, 16996, 2131, 5708, 2013, 9680, 6591, 950...\n",
              "\n",
              "[324797 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ2JloYOrdKr",
        "outputId": "43204d2e-77b2-40c6-97e1-387565ae92bf"
      },
      "source": [
        "df_selected.at[0, 'bertencodeplus']\n",
        "print(type(df_selected.at[0, 'bertencodeplus']))"
      ],
      "id": "oQ2JloYOrdKr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfTBFcY1TyN4",
        "outputId": "4c549c50-59d8-4dec-d559-bdf8190d570e"
      },
      "source": [
        "wdf = pd.DataFrame(bertidvoc)\n",
        "wdf.columns = ['id']\n",
        "print(wdf)\n",
        "wdf['word'] = wdf.apply(lambda row: btokenizer.convert_ids_to_tokens(row['id'].item()) , axis=1)\n",
        "\n",
        "\n",
        "#print(df_selected.at[0,'bertregex'])\n",
        "print(wdf.value_counts()[:30])"
      ],
      "id": "pfTBFcY1TyN4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             id\n",
            "0          2813\n",
            "1          2358\n",
            "2          1012\n",
            "3          4139\n",
            "4          5963\n",
            "...         ...\n",
            "16120608   2461\n",
            "16120609   4433\n",
            "16120610  11214\n",
            "16120611   7483\n",
            "16120612   1012\n",
            "\n",
            "[16120613 rows x 1 columns]\n",
            "id    word\n",
            "1996  the     570053\n",
            "1012  .       556314\n",
            "1010  ,       447633\n",
            "1011  -       342588\n",
            "2000  to      314317\n",
            "1037  a       311593\n",
            "1999  in      288246\n",
            "1997  of      279441\n",
            "1025  ;       199943\n",
            "1998  and     184938\n",
            "1055  s       167212\n",
            "2006  on      155590\n",
            "1001  #       152843\n",
            "4464  39      149113\n",
            "2005  for     133895\n",
            "1006  (        88343\n",
            "1007  )        87552\n",
            "2015  ##s      87493\n",
            "2004  as       74364\n",
            "2012  at       74136\n",
            "2008  that     73026\n",
            "2007  with     71367\n",
            "1005  '        70370\n",
            "2003  is       55944\n",
            "2011  by       55901\n",
            "2056  said     54886\n",
            "2010  his      53739\n",
            "1024  :        53407\n",
            "2038  has      51516\n",
            "2149  us       51281\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blxtoSlen6de",
        "outputId": "97c13168-dfc4-4677-fa55-82ebe93454a6"
      },
      "source": [
        "i = 0\n",
        "category_dictionary = []\n",
        "for s in selected_cats:\n",
        "  category_dictionary.append(tuple((i,s)))\n",
        "  i = i + 1\n",
        "print(category_dictionary)"
      ],
      "id": "blxtoSlen6de",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 'World'), (1, 'Entertainment'), (2, 'Sports'), (3, 'Business'), (4, 'Top Stories')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fc25c76"
      },
      "source": [
        "# Since the goal of this exercise if to identify category based on headline and short description, \n",
        "# we choose to merge them, as the vectorizer functions can't process multiple columns\n",
        "X = df_selected['title']+df_selected['desc']\n",
        "y = df_selected['cat']"
      ],
      "id": "4fc25c76",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2021b25",
        "outputId": "c057b925-8766-4350-e179-7358aad34576"
      },
      "source": [
        "X.describe()"
      ],
      "id": "f2021b25",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count                                                324797\n",
              "unique                                               221234\n",
              "top       ADV: Try Currency Trading Risk-Free 30 Days24-...\n",
              "freq                                                     60\n",
              "dtype: object"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71830247",
        "outputId": "5f5c718a-f758-4190-be36-1cc7ba50b6e8"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into 70-30 i.e. test size of 30% to check the accuracy of the training\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle = True)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.25, random_state=42, shuffle = True)\n",
        "\n",
        "#Let's check the shape of the splitted data\n",
        "print(f\"Training Data Shape: {X_train.shape}\")\n",
        "print(f\"Testing Data Shape: {X_test.shape}\")"
      ],
      "id": "71830247",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Data Shape: (227357,)\n",
            "Testing Data Shape: (97440,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "458e0049",
        "outputId": "0fb94658-6d8e-461c-ad8d-a34130b7c1b6"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# Let's first try with Count Vectorizer from scikit learn\n",
        "cv = CountVectorizer()\n",
        "\n",
        "X_train_cv = cv.fit_transform(X_train)\n",
        "X_train_cv.shape"
      ],
      "id": "458e0049",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(227357, 160531)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weR8Ea1BhQf3"
      },
      "source": [
        "Doing a test training with a non-deep learning model, as a test"
      ],
      "id": "weR8Ea1BhQf3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0839904",
        "outputId": "49b53b71-d48b-44c3-d4cd-07b8763b389b"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "clf = LinearSVC()\n",
        "clf.fit(X_train_cv,y_train)"
      ],
      "id": "a0839904",
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e32481c7",
        "outputId": "928dcdbc-d313-4df5-9be8-741a96494ac6"
      },
      "source": [
        "# Let's test it for the first 2 articles in the Test dataset\n",
        "X_test1 = X_test[0:2]\n",
        "print(X_test1)"
      ],
      "id": "e32481c7",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "470005    At Least 13 Killed in Philippines BlastPolice ...\n",
            "268333    Wine sparkles in dull bourseSHARES in Australi...\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f0ac8ff",
        "outputId": "4f48ca35-ee00-4317-a1c8-53615ba36905"
      },
      "source": [
        "X_test1_cv = cv.transform(X_test1)\n",
        "clf.predict(X_test1_cv)"
      ],
      "id": "3f0ac8ff",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Entertainment', 'Business'], dtype=object)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fecccb49"
      },
      "source": [
        "# Transform the test data before predicting\n",
        "X_test_cv = cv.transform(X_test)"
      ],
      "id": "fecccb49",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63cec094"
      },
      "source": [
        "# Form a prediction set\n",
        "predictions = clf.predict(X_test_cv)"
      ],
      "id": "63cec094",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fc463ed",
        "outputId": "5a049939-d487-4959-ce2c-9c8f129e852d"
      },
      "source": [
        "import sklearn.metrics as metrics\n",
        "# Report the confusion matrix\n",
        "print(metrics.confusion_matrix(y_test,predictions))\n",
        "# Print a classification report\n",
        "print(metrics.classification_report(y_test,predictions))\n",
        "# Print the overall accuracy\n",
        "print(metrics.accuracy_score(y_test,predictions))"
      ],
      "id": "9fc463ed",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[12922  1407   113  1178   827]\n",
            " [ 1661  5585  1838  8191  3852]\n",
            " [  137  1398 15316  1321   372]\n",
            " [ 1465  8344  1769  1679  3570]\n",
            " [  849  2891   479  2820 17456]]\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Business       0.76      0.79      0.77     16447\n",
            "Entertainment       0.28      0.26      0.27     21127\n",
            "       Sports       0.78      0.83      0.80     18544\n",
            "  Top Stories       0.11      0.10      0.10     16827\n",
            "        World       0.67      0.71      0.69     24495\n",
            "\n",
            "     accuracy                           0.54     97440\n",
            "    macro avg       0.52      0.54      0.53     97440\n",
            " weighted avg       0.53      0.54      0.53     97440\n",
            "\n",
            "0.5434934318555008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65439e1e",
        "outputId": "2536c6f5-e8a3-4974-c347-b460d1551172"
      },
      "source": [
        "y_train.value_counts()"
      ],
      "id": "65439e1e",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "World            56804\n",
              "Entertainment    49744\n",
              "Sports           43607\n",
              "Top Stories      39217\n",
              "Business         37985\n",
              "Name: cat, dtype: int64"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpK8jwQBhBMa"
      },
      "source": [
        ""
      ],
      "id": "cpK8jwQBhBMa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TsDE65M4NNY"
      },
      "source": [
        ""
      ],
      "id": "7TsDE65M4NNY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56bee7a1"
      },
      "source": [
        "#remove all files \n",
        "import shutil\n",
        "\n",
        "os.remove('newsspace200.xml.bz')\n",
        "shutil.rmtree('data')"
      ],
      "id": "56bee7a1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d925f9d9"
      },
      "source": [
        ""
      ],
      "id": "d925f9d9",
      "execution_count": null,
      "outputs": []
    }
  ]
}